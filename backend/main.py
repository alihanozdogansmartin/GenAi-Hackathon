from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Optional
import httpx
import json
import os
from datetime import datetime
from collections import defaultdict
from dotenv import load_dotenv
from openai import OpenAI
import warnings
from dotenv import load_dotenv

load_dotenv()

# Load credentials from .env file
api_key = os.getenv('GPT_OSS_API_KEY')
proxy_username = os.getenv('proxy_username')
proxy_password = os.getenv('proxy_password')
username = os.getenv("PRACTICUS_USERNAME", "")
pwd = os.getenv("PRACTICUS_PASSWORD", "")

# Verify API key is loaded
if not api_key:
    raise ValueError("GPT_OSS_API_KEY not found in .env file")
print(f"âœ… API Key loaded: {api_key[:20]}...")

proxy = f"http://{proxy_username}:{proxy_password}@172.31.53.99:8080/"
os.environ['http_proxy'] = proxy
os.environ['HTTP_PROXY'] = proxy
os.environ['https_proxy'] = proxy
os.environ['HTTPS_PROXY'] = proxy
no_proxy=".vodafone.local,localhost"
os.environ['no_proxy'] = no_proxy
os.environ['NO_PROXY'] = no_proxy
import warnings
warnings.filterwarnings('ignore')

app = FastAPI(
    title="Call Center Analysis API - WebSocket Edition",
    description="Real-time customer satisfaction analysis",
    version="2.0.0"
)

# CORS ayarlarÄ±
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI API configuration for Practicus AI
base_url = "https://practicus.vodafone.local/models/model-gateway-ai-hackathon/latest/v1"

# Initialize OpenAI client with custom HTTP client for proxy support
try:
    # Don't use proxy for internal .vodafone.local domains
    # The base_url is internal, so we should connect directly
    print(f"ðŸ”§ Connecting directly to internal endpoint (bypassing proxy)")
    
    client = OpenAI(
        base_url=base_url,
        api_key=api_key,
        http_client=httpx.Client(
            verify=False,  # SSL sertifikasÄ± doÄŸrulamasÄ±nÄ± devre dÄ±ÅŸÄ± bÄ±rak
            timeout=60.0
        )
    )
    print("âœ… OpenAI client initialized successfully")
except Exception as e:
    print(f"âš ï¸ OpenAI client initialization warning: {e}")
    client = OpenAI(base_url=base_url, api_key=api_key)

# WebSocket baÄŸlantÄ± yÃ¶neticisi
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.conversation_buffers: Dict[str, str] = defaultdict(str)
    
    async def connect(self, websocket: WebSocket, client_id: str):
        await websocket.accept()
        self.active_connections[client_id] = websocket
        print(f"âœ… Client {client_id} connected. Total connections: {len(self.active_connections)}")
    
    def disconnect(self, client_id: str):
        if client_id in self.active_connections:
            del self.active_connections[client_id]
        if client_id in self.conversation_buffers:
            del self.conversation_buffers[client_id]
        print(f"âŒ Client {client_id} disconnected. Total connections: {len(self.active_connections)}")
    
    async def send_personal_message(self, message: dict, client_id: str):
        if client_id in self.active_connections:
            await self.active_connections[client_id].send_json(message)
    
    async def broadcast(self, message: dict):
        for connection in self.active_connections.values():
            await connection.send_json(message)
    
    def append_to_buffer(self, client_id: str, text: str):
        self.conversation_buffers[client_id] += text + "\n"
    
    def get_buffer(self, client_id: str) -> str:
        return self.conversation_buffers[client_id]
    
    def clear_buffer(self, client_id: str):
        self.conversation_buffers[client_id] = ""

manager = ConnectionManager()

# Request/Response modelleri
class ConversationRequest(BaseModel):
    text: str
    conversation_id: Optional[str] = None
    metadata: Optional[Dict] = None

class Insight(BaseModel):
    type: str
    text: str

class Metrics(BaseModel):
    responseTime: str
    empathyLevel: str
    problemResolved: bool
    customerEmotion: str

class AnalysisResponse(BaseModel):
    overallScore: int
    sentiment: int
    resolution: int
    agentPerformance: int
    insights: List[Insight]
    metrics: Metrics
    timestamp: str
    conversation_id: Optional[str] = None

# GPT-OSS-20B Prompt Template
ANALYSIS_PROMPT = """AÅŸaÄŸÄ±daki mÃ¼ÅŸteri hizmetleri konuÅŸmasÄ±nÄ± detaylÄ± bir ÅŸekilde analiz et ve SADECE JSON formatÄ±nda yanÄ±t ver.

KonuÅŸma:
{conversation_text}

Analiz kriterleri:
1. sentiment: MÃ¼ÅŸterinin genel duygu durumu (1-10 arasÄ± sayÄ±)
2. resolution: Problemin Ã§Ã¶zÃ¼m kalitesi (1-10 arasÄ± sayÄ±)
3. agentPerformance: Temsilcinin performansÄ± (1-10 arasÄ± sayÄ±)
4. insights: Ä°Ã§gÃ¶rÃ¼ler dizisi (array) - En az 2, en fazla 5 iÃ§gÃ¶rÃ¼
5. metrics: Ek metrikler nesnesi

JSON formatÄ± (baÅŸka hiÃ§bir ÅŸey yazma):
{{
  "sentiment": sayÄ±,
  "resolution": sayÄ±,
  "agentPerformance": sayÄ±,
  "insights": [{{"type": "success/warning/info", "text": "aÃ§Ä±klama"}}],
  "metrics": {{
    "responseTime": "HÄ±zlÄ±/Orta/YavaÅŸ",
    "empathyLevel": "YÃ¼ksek/Orta/DÃ¼ÅŸÃ¼k",
    "problemResolved": boolean,
    "customerEmotion": "Pozitif/NÃ¶tr/Negatif"
  }}
}}"""

async def call_gpt_oss_20b(conversation_text: str) -> Dict:
    """GPT-OSS-20B modelini Ã§aÄŸÄ±r ve analiz yap"""
    
    prompt = ANALYSIS_PROMPT.format(conversation_text=conversation_text)
    
    messages = [
        {
            "role": "system",
            "content": "Sen bir mÃ¼ÅŸteri hizmetleri analiz uzmanÄ±sÄ±n. Sadece JSON yanÄ±t ver."
        },
        {
            "role": "user",
            "content": prompt
        }
    ]
    
    try:
        response = client.chat.completions.create(
            model="practicus/gpt-oss-20b-hackathon",
            messages=messages,
            temperature=0.3,
            max_tokens=1500,
            top_p=0.9,
            frequency_penalty=0.5,
            presence_penalty=0.3,
            seed=-1,
            extra_body={
                "metadata": {
                    "username": username,
                    "pwd": pwd,
                }
            }
        )
        
        model_response = response.choices[0].message.content
        
        # JSON temizleme
        model_response = model_response.strip()
        if model_response.startswith("```json"):
            model_response = model_response[7:]
        if model_response.startswith("```"):
            model_response = model_response[3:]
        if model_response.endswith("```"):
            model_response = model_response[:-3]
        model_response = model_response.strip()
        
        analysis = json.loads(model_response)
            
            # Genel skoru hesapla
        overall_score = round(
            (analysis["sentiment"] + analysis["resolution"] + analysis["agentPerformance"]) / 3
        )
            
        analysis["overallScore"] = overall_score
            
        return analysis
            
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"GPT-OSS-20B Error: {e}")
        print(f"Error detail:\n{error_detail}")
        raise HTTPException(status_code=500, detail=f"Model API error: {str(e)}")

# REST API Endpoints (Ã¶nceki gibi)
@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "status": "online",
        "service": "Call Center Analysis API - WebSocket Edition",
        "version": "2.0.0",
        "websocket": "/ws/{client_id}",
        "connections": len(manager.active_connections)
    }
@app.post("/api/analyze", response_model=AnalysisResponse)
async def analyze_conversation(request: ConversationRequest):
    """Tek konuÅŸma analizi (REST endpoint)"""
    
    if not request.text or len(request.text.strip()) == 0:
        raise HTTPException(status_code=400, detail="KonuÅŸma metni boÅŸ olamaz")
    
    try:
        analysis = await call_gpt_oss_20b(request.text)
        
        response = AnalysisResponse(
            overallScore=analysis["overallScore"],
            sentiment=analysis["sentiment"],
            resolution=analysis["resolution"],
            agentPerformance=analysis["agentPerformance"],
            insights=[Insight(**insight) for insight in analysis["insights"]],
            metrics=Metrics(**analysis["metrics"]),
            timestamp=datetime.now().isoformat(),
            conversation_id=request.conversation_id
        )
        
        return response
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# WebSocket Endpoint - GERÃ‡EK ZAMANLI ANALÄ°Z
@app.websocket("/ws/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str):
    """
    WebSocket endpoint - GerÃ§ek zamanlÄ± konuÅŸma analizi
    
    Client mesaj formatlarÄ±:
    
    1. KonuÅŸma parÃ§asÄ± ekle:
    {
        "type": "add_text",
        "text": "MÃ¼ÅŸteri: Merhaba..."
    }
    
    2. Analiz yap:
    {
        "type": "analyze"
    }
    
    3. Buffer'Ä± temizle:
    {
        "type": "clear"
    }
    
    4. CanlÄ± konuÅŸma modu (her mesajda otomatik analiz):
    {
        "type": "live_mode",
        "enabled": true
    }
    """
    
    await manager.connect(websocket, client_id)
    live_mode = False
    
    try:
        # HoÅŸ geldin mesajÄ±
        await manager.send_personal_message({
            "type": "connected",
            "message": "WebSocket baÄŸlantÄ±sÄ± kuruldu",
            "client_id": client_id,
            "timestamp": datetime.now().isoformat()
        }, client_id)
        
        while True:
            # Client'tan mesaj al
            data = await websocket.receive_json()
            message_type = data.get("type")
            
            # Mesaj tipine gÃ¶re iÅŸlem yap
            if message_type == "add_text":
                # KonuÅŸma parÃ§asÄ± ekle
                text = data.get("text", "")
                manager.append_to_buffer(client_id, text)
                
                # Onay mesajÄ± gÃ¶nder
                await manager.send_personal_message({
                    "type": "text_added",
                    "message": "Metin eklendi",
                    "current_buffer": manager.get_buffer(client_id),
                    "timestamp": datetime.now().isoformat()
                }, client_id)
                
                # Live mode aktifse otomatik analiz yap
                if live_mode:
                    buffer = manager.get_buffer(client_id)
                    if buffer.strip():
                        await manager.send_personal_message({
                            "type": "analyzing",
                            "message": "Analiz yapÄ±lÄ±yor...",
                            "timestamp": datetime.now().isoformat()
                        }, client_id)
                        
                        try:
                            analysis = await call_gpt_oss_20b(buffer)
                            
                            await manager.send_personal_message({
                                "type": "analysis_result",
                                "analysis": analysis,
                                "timestamp": datetime.now().isoformat()
                            }, client_id)
                        except Exception as e:
                            await manager.send_personal_message({
                                "type": "error",
                                "message": f"Analiz hatasÄ±: {str(e)}",
                                "timestamp": datetime.now().isoformat()
                            }, client_id)
            
            elif message_type == "analyze":
                # Manuel analiz tetikle
                buffer = manager.get_buffer(client_id)
                
                if not buffer.strip():
                    await manager.send_personal_message({
                        "type": "error",
                        "message": "Analiz iÃ§in metin bulunamadÄ±",
                        "timestamp": datetime.now().isoformat()
                    }, client_id)
                    continue
                
                # Analiz baÅŸladÄ± mesajÄ±
                await manager.send_personal_message({
                    "type": "analyzing",
                    "message": "Analiz yapÄ±lÄ±yor...",
                    "timestamp": datetime.now().isoformat()
                }, client_id)
                
                try:
                    # GPT-OSS-20B ile analiz yap
                    analysis = await call_gpt_oss_20b(buffer)
                    
                    # SonuÃ§larÄ± gÃ¶nder
                    await manager.send_personal_message({
                        "type": "analysis_result",
                        "analysis": analysis,
                        "conversation": buffer,
                        "timestamp": datetime.now().isoformat()
                    }, client_id)
                    
                except Exception as e:
                    await manager.send_personal_message({
                        "type": "error",
                        "message": f"Analiz hatasÄ±: {str(e)}",
                        "timestamp": datetime.now().isoformat()
                    }, client_id)
            
            elif message_type == "clear":
                # Buffer'Ä± temizle
                manager.clear_buffer(client_id)
                
                await manager.send_personal_message({
                    "type": "cleared",
                    "message": "Buffer temizlendi",
                    "timestamp": datetime.now().isoformat()
                }, client_id)
            
            elif message_type == "live_mode":
                # Live mode aÃ§/kapat
                live_mode = data.get("enabled", False)
                
                await manager.send_personal_message({
                    "type": "live_mode_changed",
                    "enabled": live_mode,
                    "message": f"CanlÄ± analiz modu {'aÃ§Ä±ldÄ±' if live_mode else 'kapatÄ±ldÄ±'}",
                    "timestamp": datetime.now().isoformat()
                }, client_id)
            
            elif message_type == "ping":
                # Keepalive
                await manager.send_personal_message({
                    "type": "pong",
                    "timestamp": datetime.now().isoformat()
                }, client_id)
            
            else:
                await manager.send_personal_message({
                    "type": "error",
                    "message": f"Bilinmeyen mesaj tipi: {message_type}",
                    "timestamp": datetime.now().isoformat()
                }, client_id)
    
    except WebSocketDisconnect:
        manager.disconnect(client_id)
    except Exception as e:
        print(f"WebSocket Error for {client_id}: {e}")
        manager.disconnect(client_id)

@app.get("/api/stats")
async def get_stats():
    """WebSocket istatistikleri"""
    return {
        "active_connections": len(manager.active_connections),
        "active_clients": list(manager.active_connections.keys()),
        "timestamp": datetime.now().isoformat()
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)